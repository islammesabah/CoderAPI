{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99b358ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0dc43b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf255be",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d2b0529",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = {\n",
    "    'general': (\n",
    "    \"Below is an instruction that describes a task. \"\n",
    "        \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "        \"### Instruction:\\n{instruction}\\n\\n### Response:\"\n",
    "    )\n",
    "}\n",
    "max_len = 512\n",
    "device = \"cuda\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e207f0d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f94c29c207e84538aaf8d90a09c0fc54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "993ee55182ec4a6f93c15566a9ea8a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1c8bcf533fc4386987e891828e905b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path = '../Datasets/pairs_data/cleaned_data/data_test.json'\n",
    "datasets = load_dataset('json', data_files=file_path)['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e79c3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['output', 'instruction', 'input', 'api'],\n",
       "    num_rows: 127\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428c2c3a",
   "metadata": {},
   "source": [
    "## Embedding Documentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbc0fa7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_name = '../Training/saved_models/Salesforce/instructcodet5p-16b'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78965ac1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1f5c4b146eb46599c80a8c433758ef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)iguration_codet5p.py:   0%|          | 0.00/4.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/Salesforce/instructcodet5p-16b:\n",
      "- configuration_codet5p.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34bddcfa96e34ec9abb979aa73e3a0c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading modeling_codet5p.py:   0%|          | 0.00/43.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/Salesforce/instructcodet5p-16b:\n",
      "- modeling_codet5p.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3577bbed06f24ae1ad89acb9683c1625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CodeT5pEncoderDecoderModel(\n",
       "  (encoder): CodeT5pModel(\n",
       "    (wte): Embedding(51200, 1024)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-19): 20 x CodeT5pBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CodeT5pAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (mlp): CodeT5pMLP(\n",
       "          (fc_in): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc_out): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): CodeT5pForCausalLM(\n",
       "    (transformer): CodeT5pModel(\n",
       "      (wte): Embedding(51200, 6144)\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "      (h): ModuleList(\n",
       "        (0-32): 33 x CodeT5pBlock(\n",
       "          (ln_1): LayerNorm((6144,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): CodeT5pAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv_proj): Linear(in_features=6144, out_features=18432, bias=False)\n",
       "            (out_proj): Linear(in_features=6144, out_features=6144, bias=False)\n",
       "          )\n",
       "          (mlp): CodeT5pMLP(\n",
       "            (fc_in): Linear(in_features=6144, out_features=24576, bias=True)\n",
       "            (fc_out): Linear(in_features=24576, out_features=6144, bias=True)\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (33): CodeT5pBlock(\n",
       "          (ln_1): LayerNorm((6144,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): CodeT5pAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv_proj): Linear(in_features=6144, out_features=18432, bias=False)\n",
       "            (out_proj): Linear(in_features=6144, out_features=6144, bias=False)\n",
       "          )\n",
       "          (mlp): CodeT5pMLP(\n",
       "            (fc_in): Linear(in_features=6144, out_features=24576, bias=True)\n",
       "            (fc_out): Linear(in_features=24576, out_features=6144, bias=True)\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (crossattention): CodeT5pAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv_proj): Linear(in_features=6144, out_features=12288, bias=False)\n",
       "            (q_attn): Linear(in_features=6144, out_features=6144, bias=False)\n",
       "            (out_proj): Linear(in_features=6144, out_features=6144, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((6144,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=6144, out_features=51200, bias=True)\n",
       "  )\n",
       "  (enc_to_dec_proj): Linear(in_features=1024, out_features=6144, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name,\n",
    "                                              torch_dtype=torch.float16,\n",
    "                                              low_cpu_mem_usage=True, \n",
    "                                              trust_remote_code=True, \n",
    "                                              device_map='auto'\n",
    "                                             )\n",
    "model.tie_weights()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92a61e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Create a Python program that retrieves the metadata of a file on Google Drive using the PyDrive2 API. The program should take the file ID as input and display the metadata information of the file, including its title, size, creation date, and last modified date. Make sure the program is capable of handling cases where the file ID provided is invalid or when there is an authentication issue.\n",
      "\n",
      "### Response: Find geop frank cit Pic frank gap frank bas Loc frank gr frank bas Loc frank cit Pic ge frank bas Loc ge frank cit Pic ge frank bas Loc ge frank cit frank bas Loc ge frank cit frank bas frank bas Loc ge frank cit frank cit ge\n"
     ]
    }
   ],
   "source": [
    "def embedding_docu_with_decoder(model, tokenizer, prompt, docs):\n",
    "    prompt_tok = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=5000,                    \n",
    "        chunk_overlap=300,                  \n",
    "        add_start_index=True\n",
    "    )\n",
    "    \n",
    "    all_splits = text_splitter.split_text(docs)\n",
    "    \n",
    "    f_split_tok = tokenizer(all_splits[0], return_tensors=\"pt\").to(device)\n",
    "    encoding_split = model.encoder(**f_split_tok)\n",
    "    encoding_split = model.enc_to_dec_proj(encoding_split.last_hidden_state)\n",
    "    encoding_prompt = model.decoder.transformer(\n",
    "        input_ids=prompt_tok[\"input_ids\"],\n",
    "        attention_mask=prompt_tok[\"attention_mask\"],\n",
    "        encoder_hidden_states=encoding_split,\n",
    "        encoder_attention_mask=f_split_tok[\"attention_mask\"]).last_hidden_state\n",
    "    \n",
    "    for split in all_splits[1:]:\n",
    "        split_tok = tokenizer(split, return_tensors=\"pt\").to(device)\n",
    "        encoding_split_out = model.encoder(**split_tok)\n",
    "        encoding_split = model.enc_to_dec_proj(encoding_split_out.last_hidden_state)\n",
    "        encoding_prompt = model.decoder.transformer.h[33].crossattention(\n",
    "            hidden_states = encoding_prompt,\n",
    "            attention_mask = f_split_tok.attention_mask,\n",
    "            encoder_hidden_states = encoding_split,\n",
    "            encoder_attention_mask = split_tok.attention_mask\n",
    "        )[0]\n",
    "    encoding_split_out.past_key_values = None\n",
    "    encoding_split_out.last_hidden_state = encoding_prompt\n",
    "    return encoding_split_out\n",
    "        \n",
    "prompt_type = 'general'\n",
    "prompt = PROMPT[prompt_type]\n",
    "inst = datasets[0]\n",
    "d = inst[\"input\"]\n",
    "p = prompt.format_map({'instruction': inst[\"instruction\"]})\n",
    "encoder_outputs = embedding_docu_with_decoder(model, tokenizer, p, d)\n",
    "prompt_tok = tokenizer(p, return_tensors=\"pt\").to(device)\n",
    "model.encoder.config.hidden_size = model.decoder.config.hidden_size\n",
    "outputs = model.generate(\n",
    "                decoder_input_ids = prompt_tok[\"input_ids\"],\n",
    "                decoder_attention_mask = prompt_tok[\"attention_mask\"],\n",
    "                encoder_outputs = encoder_outputs,\n",
    "                max_new_tokens=50,\n",
    "                pad_token_id=tokenizer.eos_token_id)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "763eabcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Create a Python program that retrieves the metadata of a file on Google Drive using the PyDrive2 API. The program should take the file ID as input and display the metadata information of the file, including its title, size, creation date, and last modified date. Make sure the program is capable of handling cases where the file ID provided is invalid or when there is an authentication issue.\n",
      "\n",
      "### Response:enHaUk routes bitsï¿½ proc\t\t\t\t ardu phantom routes procaciaci ferry proc\t\t\t\t procaciaci ge picture routesaci frankaci geop Procaci proc greenhouse Procaci Procaci Procaci Procaci Procaci Procaci Procaci Procaci Procaci Procaci Procaci Procaci Procaci Procaci Procaci Procaci Procaci Procaci Procaci Procaci Procaci Procaci Procaci Procaci ProcaciHa procaciaciaci frankaciaci procaciaci proc phantom proc phantom procaciaci frankaci Procaci Procaci frankaci frankaci Procaci Procaci Procaci Procaci Procaci Procaci Procaci Procaci Procaci Procaci Procaci Procaci Procge procHa Procge proc geop Proc known procaciaciaci known proc geop proc known proc phantom Proc phantom proc geop proc known procge proc known procge proc known procge Procaci known Procge proc known procge proc known procge procunknown Procaci known Procge procunknown procaciaciaci known procaciaciaci known procge proc geop Proc known Procge proc geop proc known Procge Procge Proc geop proc geop Procaci known Procge proc geop proc known procge proc known procge procaciaciaci known Procï¿½ Proc geop proc known procge Procge proc known procge Procge procge procaciaciaci known procge proc geop proc known procge procge proc geop Procge Procge proc geop proc known procge Procge Procge Geo proc known procge proc known procge procge procge Procge procge Procge Op\t\t\t\t known procge frankaci procge frankaci known procge frankaci procaciaciaciaciaciaciaciaciaciaciaciaciaci geop rover Procaci known procge proc geop Proc geop proc geop Proc geop Proc geop Proc geop Procgege proc geop proc known procaciaciaciaciaci geop rover Procaci known procge proc geop procavi Proc geop proc geop Procaciaci geop geop geop Procgege proc park Procaciaciaci geop park Procaci geop park geop proc park Procaci known procge rook known procge known procge known procge known procge Procge proc geop geop geop Proc phantom geop geop geop geop park Proc rac procaci known proc park procaciaci known proc park Proc park geop geop park Proc park known known proc park known known known known known known known known known known known known known known known known known known known known known known known known known known known known known known known known known known known known known known knownrequ Procaciaciaciaciaci\n"
     ]
    }
   ],
   "source": [
    "def embedding_docu_with_encoder(model, tokenizer, prompt, docs):\n",
    "    prompt_tok = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    encoding_prompt = model.encoder(**prompt_tok)\n",
    "    encoding_prompt = model.enc_to_dec_proj(encoding_prompt.last_hidden_state)\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=5000,                    \n",
    "        chunk_overlap=300,                  \n",
    "        add_start_index=True\n",
    "    )\n",
    "    \n",
    "    all_splits = text_splitter.split_text(docs)\n",
    "    \n",
    "    f_split_tok = tokenizer(all_splits[0], return_tensors=\"pt\").to(device)\n",
    "    encoding_split = model.encoder(**f_split_tok)\n",
    "    encoding_split = model.enc_to_dec_proj(encoding_split.last_hidden_state)\n",
    "    encoding_prompt = model.decoder.transformer.h[33].crossattention(\n",
    "            hidden_states = encoding_split,\n",
    "            attention_mask = f_split_tok.attention_mask,\n",
    "            encoder_hidden_states = encoding_prompt,\n",
    "            encoder_attention_mask = prompt_tok.attention_mask\n",
    "        )[0]\n",
    "    \n",
    "    for split in all_splits[1:]:\n",
    "        split_tok = tokenizer(split, return_tensors=\"pt\").to(device)\n",
    "        encoding_split_out = model.encoder(**split_tok)\n",
    "        encoding_split = model.enc_to_dec_proj(encoding_split_out.last_hidden_state)\n",
    "        encoding_prompt = model.decoder.transformer.h[33].crossattention(\n",
    "            hidden_states = encoding_prompt,\n",
    "            attention_mask = f_split_tok.attention_mask,\n",
    "            encoder_hidden_states = encoding_split,\n",
    "            encoder_attention_mask = split_tok.attention_mask\n",
    "        )[0]\n",
    "\n",
    "    encoding_split_out.last_hidden_state = encoding_prompt\n",
    "    return encoding_split_out\n",
    "        \n",
    "prompt_type = 'general'\n",
    "prompt = PROMPT[prompt_type]\n",
    "inst = datasets[0]\n",
    "\n",
    "d = inst[\"input\"]\n",
    "p = prompt.format_map({'instruction': inst[\"instruction\"]})\n",
    "encoder_outputs = embedding_docu_with_encoder(model, tokenizer, p, d)\n",
    "prompt_tok = tokenizer(p, return_tensors=\"pt\").to(device)\n",
    "model.encoder.config.hidden_size = model.decoder.config.hidden_size\n",
    "outputs = model.generate(\n",
    "                decoder_input_ids = prompt_tok[\"input_ids\"],\n",
    "                decoder_attention_mask = prompt_tok[\"attention_mask\"],\n",
    "                encoder_outputs = encoder_outputs,\n",
    "                max_new_tokens=max_len,\n",
    "                pad_token_id=tokenizer.eos_token_id)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce796cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
